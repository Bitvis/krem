# Copyright (C) 2017  Bitvis AS
#
# This file is part of KREM.
#
# KREM is free software: you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
# the Free Software Foundation, either version 3 of the License, or
# (at your option) any later version.
#
# KREM is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
# GNU General Public License for more details.
#
# You should have received a copy of the GNU General Public License
# along with KREM.  If not, see <http://www.gnu.org/licenses/>.
#
#
# Bitvis AS 
# www.bitvis.no
# info@bitvis.no


------------------------------------------------------------------
ABOUT THIS MANUAL
------------------------------------------------------------------
This manual covers KREM v2.0.0




------------------------------------------------------------------
INSTALLATION
------------------------------------------------------------------

Clone or copy KREM to any location and run:
./setup.sh

In case the above script fails update the PATH and PYTHONPATH environment variables as follows:

export PATH=$PATH:<path to krem>/krem
export PYTHONPATH=$PYTHONPATH:<path to krem>/krem

Hint: add the above lines to the ~/.bashrc file and the paths will be setup automatically every time you open a new terminal.

------------------------------------------------------------------
USAGE
------------------------------------------------------------------

$ krem --help

Available commands:
- init
- run
- list

for more information, execute: krem <cmd> --help

$ krem init --help
$ krem list --help
$ krem run  --help


------------------------------------------------------------------
TUTORIAL
------------------------------------------------------------------

1. Create your first project 'project_foo'
	To create a project 'project_foo' run:

	$ krem init -p project_foo

	A directory 'project_foo' is created with several subdirectories:
	'config  library  output  jobs  tasks'
	Each directory will be explained later in this tutorial.


2. Enter 'project_foo'

	$ cd project_foo


3. Create your first job 'job_foo'
	A job is a list of tasks run in series, in parallel or a combination of both.
	The order is specified by the user.
	Each job has its own directory which is located in the 'jobs' directory.
	When a job is created, a template file 'job.py' is placed in the job directory.
	To create a job 'job_foo' run:

	$ krem init -j job_foo

	This will create a job directory 'jobs/job_foo' and place a 'job.py' file in the directory.


4. Quick look at the 'job.py' file
	Open the 'jobs/job_foo/job.py file and take a quick look.
	This template file can be run for demonstration without modification.
	The content of the file is explained later in this tutorial.


5. Create your first task 'task_foo'
	Each task has its own directory which is located in the 'tasks' directory.
	When a task is created, a template file 'task.py' is placed in the task directory.
	To create a 'task_foo' task run:

	$ krem init -t task_foo

	This will create a task directory 'tasks/task_foo/' and place the files 'task.py', '__init__.py' in the directory.

6. Quick look at the 'task.py' file
	Open the 'tasks/task_foo/task.py' file and take a look.
	This template file can be run for demonstration without modification.
	Study the file for few seconds.
	An argument 'task' is passed to every task function. This argument is inserted by KREM and is mandatory for all task functions.
	For more information on the 'task' argument see 'Advanced features' section below.
	Note the return error codes. A task can return at any point with an appropriate error code.


7. Running the template job
    Once you have created a job and a task from the template, as described above, you are ready to execute it.
    To execute the job 'job_foo' run:

    $ krem run -j job_foo

   	Optionally, you can first call:

	$ krem list -j

	All available jobs are listed with a number ID (if 'job_foo' is the only available job, it will have the number ID '0').
	To run 'job_foo' with number ID, run:

	$ krem run -j 0

	The job is run and when it finish, a report is output. Hopefully your tasks passed :-)


8. Job template explained
	Now go back to the file 'job.py' in directory 'job_foo'.
	The below line specifies that function 'run_without_arguments' in task 'task_foo' will be run first.

	    err = job.run_task_serial('task_foo', 'run_without_arguments')

	If the above task passes, the below task will be executed. In this case a list is passed to the task function.

	    err = job.run_task_serial('task_foo', 'run_with_argument_list', arguments=["argument passed from job", "as list"])

	It is also possible to pass named arguments to a task function as shown below

	    err = job.run_task_serial('task_foo', 'run_with_named_arguments', arguments=[("arg1", "arg1_value"), ("arg2", "arg2_value")])


	The template job file also includes parallel task execution.
	First, you have to add tasks for parallel execution as shown below.
    Then, call 'job.wait_for_complete()' to trigger parallel execution. 'job.wait_for_complete()' will return once all of the above tasks
    finish and return.

        job.run_task_parallel('task_foo', 'run_with_named_arguments', arguments=[("arg1", ""), ("arg2", "run_in_parallel")])
        job.run_task_parallel('task_foo', 'run_with_named_arguments', arguments=[("arg1", "also"), ("arg2", "run_in_parallel")])

        job.wait_for_complete() # Wait until parallel tasks are complete, and return result



9. Find your task results
	Each time a job is run, the result and logs are written to a new directory in the 'output' directory.
	Change to 'output' directory and list all entries:

	$ cd output
	$ ls -l

	-rw-rw-r-- 1 mk mk   35 feb.   9 14:45 info
	drwxrwxr-x 3 mk mk 4096 feb.   9 14:45 job_foo

	Change to 'job_foo' directory and list all entries:

	$ cd job_foo
	$ ls -l

	drwxrwxr-x 7 mk mk 4096 feb.   9 14:45 20180209_144547
	lrwxrwxrwx 1 mk mk   15 feb.   9 14:45 latest -> 20180209_144547

	The first time a job is run, a new directory for this job is created in the output directory.
	For each run a directory with a timestamp is created in the job output directory. There is also a symbolic link,
	named 'latest', pointing at the latest timestamped directory.
	The 'info' file is not relevant for this tutorial.

10. Browse job results
	Enter the latest directory through the link and list all entries:

	$ cd latest
	$ ls -l

	drwxrwxr-x 2 mk mk 4096 feb.   9 14:45 1_1_task_foo_run_without_arguments
	drwxrwxr-x 2 mk mk 4096 feb.   9 14:45 2_1_task_foo_run_with_argument_list
	drwxrwxr-x 2 mk mk 4096 feb.   9 14:45 3_1_task_foo_run_with_named_arguments
	drwxrwxr-x 2 mk mk 4096 feb.   9 14:45 4_1_task_foo_run_with_named_arguments
	drwxrwxr-x 2 mk mk 4096 feb.   9 14:45 4_2_task_foo_run_with_named_arguments
	-rw-rw-r-- 1 mk mk  407 feb.   9 14:45 execution.log
	-rw-rw-r-- 1 mk mk  499 feb.   9 14:45 results
	-rw-rw-r-- 1 mk mk 1035 feb.   9 14:45 tasks.log

	There is a separate directory for each task added with function 'job.run_task_...(...)' in the 'job.py' file. This
	directory is the task output folder. The path to the task output folder is accessible from task.get_output_path,
	which can be retrieved at task initialization (see "ADVANCED FEATURES" below). Each directory name starts with the 
	number representing the order as they are called in the job. For parallel tasks, this number will be the same. 
	Then follows the task name, and the target function that was called. The final number represents order of execution. 
	This is only of relevance for parallel tasks.

	The 'results' file holds the result report as was output on the screen after the job finished.
	The 'execution.log' file is a log for the job.
    The 'tasks.log' file is a log for all the tasks. It contains all output produced by the tasks as
    it would otherwise be printed to the screen if the task was run directly from command line.

	ENJOY!



------------------------------------------------------------------
ADVANCED FEATURES
------------------------------------------------------------------
1. 'task' argument in task functions
    An argument 'task' is passed to every task function. This argument is inserted by KREM and is mandatory for all task functions.

	'task' is an object with information on the current task as follows:
	    - task_name (the current task name)
	    - run_name (the current task name including the run number and current task function)
	    - run_nr (run number of the current task. This number is incremented for every task added in the job)
	    - full_run_nr (run_nr + '1' for serial task or additional run number for parallel tasks)
	    - job_output_path (path to the current job directory in the output directory)
	    - output_path (path to the current task directory in the output directory. This is where you can save files from your task if applicable)

	The following 'task' getter functions return the above properties:
	  def get_task_name(self):
	  def get_run_name(self):
	  def get_run_nr(self):
	  def get_full_run_nr(self):
	  def get_job_path(self):
	  def get_output_path(self):

	WARNING: The task object provides also several setter functions. These function shall not be used by the task.
                 These might break the job if used.


	
2. Add runtime plugins
	Runtime plugins provide additional functionality during job/task execution. There are several entry points (aka calls to callback functions) as listed below
	You can choose whether to implement all or just some of the above in your plugin.
	
    def job_start(self, job):
        # this function is executed at the beginning of a job 
        # (at the beginning of the job.start() function)
    
    def pre_task_execution(self, task, job):
        # this function is executed just before a task is executed
    
    def pre_task_function_call(self, task):
        # this function is executed just before a task function is called
    
    def post_task_function_call(self, task):
        # this function is executed right after a task function has returned
    
    def post_task_execution(self, task, job):
        # In case of a serial task, this function is executed right after a task has finished and the task result is ready
        # In case of parallel tasks, this function is executed when the wait_for_complete function is called in a job
    
    def job_end(self, job):
        # this function is executed at the end of a job 
        # (at the end of the job.end() function)
        
	


	The following instructions explain how to setup a target job to use an existing plugin.

	1. Clone the krem_plugins repository (https://github.com/Bitvis/krem_plugins.git) directly into '<krem_project>/library/plugins'. 
           The plugins you will use in your project is located in <krem_project>/library/plugins/krem_plugins/print_task_results/print_task_results.py 

	2. Register the plugin in the plugin setup function located in the file '<krem_project>/library/setup.py'. This file must contain the following:

		from krempack.core import plugin
		from from library.plugins.krem_plugins.print_task_results import print_task_results

		def setup_plugins(plugin_handler):
		    # Register all plugins you want to use here
		    plugin_handler.register_plugin(print_task_results.PluginPrintTaskResults)

	   where PluginPrintTaskResults is the class, located in 'print_task_results.py'.

	3. Import setup_plugins and execute it inside the job script (the job template is already populated with the below). In '<krem_task>/jobs/<job>/job.py':

		...
		from library.setup import setup_plugins

		...
		setup_plugins(job.plugin_handler)

    		# Initialize job
    		job.start()

------------------------------------------------------------------
FAQ
------------------------------------------------------------------

Q: Can I have more than one job in the same project?
A: Yes, you can create as many jobs as you want?

Q: Can I add the same tasks in several jobs?
A: Yes, the same tasks can be added to several jobs. 
   Actually, it is recommended to write tasks in such a way that they can be reused in more that one job.

Q: Can the job abort instantly if one of the tasks fail? 
A: Yes. All tasks returns the result as a returncode (directly from job.run_task_serial(...) or from job.wait_for_complete
   for parallel tasks). Write the job to check the returncode from the tasks to see if job execution should 
   continue or not. 

Q: What is the 'library' directory?
A: You can place plugins and your python modules specific to the project in this directory.

Q: What is the 'config' directory?
A: User can place any configuration needed by jobs and tasks in current project. KREM does not care about this directory.

Q: Can I copy my project to other locations or even to other computers?
A: Yes, as long as you copy the whole directory structure.

Q: Can I copy my jobs and tasks to other projects?
A: Yes, as long as you copy to the corresponding locations in the project you copy to.
   Remember to also copy required modules and plugins, if any, in the 'library' directory.

Q: What Python version are supported?
A: As of latest KREM Python 2.7 and 3.6 is supported.

Q: What operating systems are supported?
A: As of latest KREM only Linux is supported. Future releases will also support Windows 10 and above.

Q: How do I uninstall KREM?
A: Simply remove the KREM directory. There are no KREM related files placed anywhere except in the KREM directory and
   within your KREM projects. You may also want to remove the path to the KREM directory from the environment variables
   PATH and PYTHONPATH, and from the file ~/.bashrc, especially if you are planning to install KREM in another location
   
Q: How do I rename/delete a task or job?
A: KREM recognize tasks and jobs by their directory as they appear in <krem_project>/tasks or <krem_project>/jobs. Simply
   remove/rename the target task/job directory.



------------------------------------------------------------------
TROUBLESHOOTING:	
------------------------------------------------------------------
P: I keep getting the following error task for all 'krem' commands I run.
   'ERROR: Project task root directory not found.'
S: You must run 'krem' from within your project directory. 
   KREM recognizes a project directory by the presence of the following directories:
   'config  library  output  jobs  tasks'
   
   Make sure that all of the above directories are present in your project directory.
   Sometimes the user deletes the 'output' directory to delete all results. Simply create the directory and try again:

   $ mkdir output 
   
P: I have a task that calls a subprocess. The printout from this subprocess is printed to the terminal instead of the
   task log. How can I log the printout from the subprocess to the task log?
S: You must direct stdout and stderr to the task log for the subprocess. Stdout and stderr have already been directed to
   the task log for the task. However, when a subprocess is called, stdout and stderr will be default set to the terminal.
   In your task, you can use sys.stdout and sys.stderr to direct output to the task log.
   
   Example: 
   import subprocess
   import sys
   '''
   your code
   '''
   subprocess.call(args, stdout=sys.stdout, stderr=sys.stderr)
   
P: Job execution stops abruptly with no error messages.
S: Check if there are any calls to exit() in the tasks executed by your job. If exit() is called during task execution,
   you will immediately exit from the job. Simply replace any calls to exit() with return().
